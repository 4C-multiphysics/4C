#-------------------------------------------------------------------------------
# General rules when to create a pipeline
# N.B. This doesn't say anything about which jobs are run but only determines
# if a pipeline is created.
workflow:
  name: $BACI_PIPELINE_NAME
  rules:
    # for merge requests
  - if: $CI_MERGE_REQUEST_IID
    variables:
      BACI_PIPELINE_NAME: MR pipeline for '$CI_MERGE_REQUEST_SOURCE_BRANCH_NAME'
        # for tags
  - if: $CI_COMMIT_TAG
    variables:
      BACI_PIPELINE_NAME: Tag pipeline for '$CI_COMMIT_TAG'
        # for a merge to the default branch
  - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    variables:
      BACI_PIPELINE_NAME: Post-merge pipeline for '$CI_COMMIT_TITLE'
  - if: $CI_PIPELINE_SOURCE == "schedule" && $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    variables:
      BACI_PIPELINE_NAME: Scheduled pipeline for '$CI_COMMIT_TITLE'
        # if manually triggered with the web interface's "run pipeline"
  - if: $CI_PIPELINE_SOURCE == "web"
    variables:
      BACI_PIPELINE_NAME: Manual pipeline for '$CI_COMMIT_BRANCH'

#-------------------------------------------------------------------------------
# Define global variables for all jobs
variables:
  # Clone repository by default, file have changed attribute.
  GIT_STRATEGY: clone
  # If not called by a scheduler this variable has to be 0.
  # 1: daily full (release, debug)
  # 3: coverage
  # 4: weekly testing of Baci with a current Trilinos develop version
  GITLAB_SCHEDULER_TYPE: '0'

  # Build type for pipelines started via the GitLab GUI
  # Options:
  # - "release" (default)
  # - "debug"
  CTEST_BUILD_TYPE_GITLAB: release

  # Variables for docker
  # Whether to build the docker images and push them to the CI registry
  BACI_DOCKER_BUILD_IMAGES: 'False'
  BACI_DOCKER_DEPENDENCIES_HASH: 47a26ae9
  BACI_DOCKER_DEPENDENCIES_IMAGE: baci-dependencies
  BACI_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH: $BACI_DOCKER_DEPENDENCIES_IMAGE:$BACI_DOCKER_DEPENDENCIES_HASH

  # Variables for Trilinos pipeline
  # The default Trilinos commit ref the Trilinos pipeline is running on
  TRILINOS_PIPELINE_COMMIT_REF: develop
  BACI_DOCKER_DEPENDENCIES_IMAGE_TRILINOS: baci-dependencies-trilinos:$TRILINOS_PIPELINE_COMMIT_REF

.compute-dependencies-hash: &compute-dependencies-hash
  # compute short hash from contents of folder dependencies and docker (exclude trilinos_config and README.md files)
- COMPUTED_DOCKER_DEPENDENCIES_HASH=`find dependencies docker -not -wholename '*/trilinos_develop/*'
  -not -name 'README.md' -type f -exec sha1sum {} \; | sort | sha1sum | cut -c -8`

before_script:
- git config --global --add safe.directory ${CI_PROJECT_DIR}
- *compute-dependencies-hash
- if [ "${COMPUTED_DOCKER_DEPENDENCIES_HASH}" != "$BACI_DOCKER_DEPENDENCIES_HASH"
  ]; then echo "Docker image version hash does not match the hash of the dependencies.
  You likely need to change the hash to ${COMPUTED_DOCKER_DEPENDENCIES_HASH} and rebuild
  the dependencies." && exit 1; else echo "Running on the correct docker image version
  with hash $BACI_DOCKER_DEPENDENCIES_HASH."; fi

#-------------------------------------------------------------------------------
# Define the base jobs for testing
#-------------------------------------------------------------------------------

# Commands to remove old build files (on shell executors)
.clean-build-folder: &clean-build-folder
  # Delete old build files.
- rm -rf ${CI_PROJECT_DIR}/../baci-build/
  # Clear eventual ccache cache.
- if [ -x "$(command -v ccache)" ]; then ccache -C -z; echo "ccache cache cleared";
  fi

.build-only: &build-only
- mkdir -p ${CI_PROJECT_DIR}/../baci-build
  # configure
- |
  if [ $CTEST_BUILD_TYPE_GITLAB == "debug" ]; then PRESET=${CTEST_BUILD_PRESETS_DEBUG_GITLAB}; else PRESET=${CTEST_BUILD_PRESETS_RELEASE_GITLAB}; fi
  cd ${CI_PROJECT_DIR}
  ./create-baci-python-venv
  cd ${CI_PROJECT_DIR}/../baci-build
  # We override the launcher arguments here to ensure that ccache is not used during testing
  ${CMAKE_COMMAND} ${CI_PROJECT_DIR} --preset=${PRESET} -DCMAKE_C_COMPILER_LAUNCHER="" -DCMAKE_CXX_COMPILER_LAUNCHER=""
- echo Building the following targets ${BUILD_TARGETS}
  # build
- time ${CMAKE_COMMAND} --build . --target ${BUILD_TARGETS} -- -j `nproc` 2>&1 | tee
  ${CI_PROJECT_DIR}/build.log

.build-and-test: &build-and-test
- *build-only
  # test
- 'echo ctest selection: $CTEST_TEST_SELECTION'
- time ${CTEST_COMMAND} -VV $CTEST_TEST_SELECTION -j `nproc` --output-junit ${CI_PROJECT_DIR}/junit_test_summary.xml
  | tee ${CI_PROJECT_DIR}/test.log | grep -e "\*\*\*Failed" -e "\.\.\.   Passed" -e
  " tests passed\,"
- cd ${CI_PROJECT_DIR}

.check-no-warnings: &check-no-warnings
- cd ${CI_PROJECT_DIR}/../baci-build
  # check for warnings
- if grep -iP "warning:" ${CI_PROJECT_DIR}/build.log; then echo 'Warnings found!'
  && exit 1; else echo 'No warnings found'; fi
- cd ${CI_PROJECT_DIR}

.post-process-log-files: &post-process-log-files
  # sort output of pipeline
- cd ${CI_PROJECT_DIR}/../baci-build
- ${CI_PROJECT_DIR}/utilities/baci-python-venv/bin/python ${CI_PROJECT_DIR}/utilities/sort_pipeline_output.py
  ${CI_PROJECT_DIR}/test.log ${CI_PROJECT_DIR}/test.log
  # Write selection of the output into the terminal and therefore to GITLAB
  # Output 200 lines for any failing test
- grep -B 200 '*Failed\|*Timeout' ${CI_PROJECT_DIR}/test.log || true
- sed -n '/tests passed,/,//p' ${CI_PROJECT_DIR}/test.log
  # Specify which configuration was tested by this pipeline
- 'echo Baci build type: $CTEST_BUILD_TYPE_GITLAB'
- 'echo Run tests matching expression: $TEST_TAG [{.} all tests, {} no test]'
- 'echo Excluded tests: $CTEST_EXCLUDE_STRING [{} no test excluded]'
  # Move the log files to the source folder, so it can be found by artifacts.
- cd ${CI_PROJECT_DIR}


# Generic job that builds and tests the project. Derived jobs may configure the details via variables.
.buildtest_base:
  stage: buildtest
  variables:
    # So the old build can be used again.
    GIT_STRATEGY: fetch
    BUILD_TARGETS: full
  script:
  - *clean-build-folder
  - *build-and-test
  - *check-no-warnings
  after_script:
  - *post-process-log-files
  artifacts:
    name: $CI_JOB_NAME-$CI_JOB_ID
    paths:
    - '*.log'
    - junit_test_summary.xml
    reports:
      junit: junit_test_summary.xml
    when: always
    expire_in: 1 day


# This kind of job is started when a user triggers a job in the gitlab UI or
# inside a MR. Full tests are performed.
.buildtest_full:
  extends: .buildtest_base
  rules:
  - if: $GITLAB_SCHEDULER_TYPE != "0"
    when: never
  - if: $CI_PIPELINE_SOURCE == "web"
  - if: $CI_MERGE_REQUEST_IID


# This kind of job is started by a scheduler, with the variable
# $GITLAB_SCHEDULER_TYPE = "3"
# Full tests with coverage are performed
# A coverage report is created
.buildtest_coverage:
  stage: buildtest
  variables:
    BUILD_TARGETS: full
  script:
  - *clean-build-folder
  - *build-and-test
    # generate the baci_coverage_base.info: the "baseline" coverage data file that contains zero coverage for every instrumented line.
  - lcov --capture --initial --no-external --directory ../baci-build/ --base-directory
    . --output-file baci_coverage_base.info > ${CI_PROJECT_DIR}/baci_coverage_base.log
    # generate the baci_coverage_tests.info based on tests run above
  - lcov --capture --no-external --directory ../baci-build/ --base-directory . --output-file
    baci_coverage_tests.info > ${CI_PROJECT_DIR}/baci_coverage_tests.log
    # combine the baseline coverage with the coverage from the tests
  - lcov --add-tracefile baci_coverage_base.info --add-tracefile baci_coverage_tests.info
    --output-file baci_coverage.info  > ${CI_PROJECT_DIR}/baci_coverage.log
    # remove unwanted files from the coveragre report
  - lcov --remove baci_coverage.info "*/unittests*/*" "*/tests/*" "*/baci-build/*"
    -o baci_coverage_filtered.info > ${CI_PROJECT_DIR}/baci_coverage_filtered.log
    # generate the html version of the coverage report
  - genhtml baci_coverage_filtered.info --legend --demangle-cpp --output-directory
    coverage_report/ --title "BACI commit $CI_COMMIT_SHORT_SHA" | tee ${CI_PROJECT_DIR}/genhtml_coverage.log
    # add repo link to the commit that the report is based on
  - find coverage_report/ -type f -exec sed -i "s/BACI commit $CI_COMMIT_SHORT_SHA/BACI
    commit  \<a 
    href=\"https:\/\/gitlab.lrz.de\/baci\/baci\/commit\/$CI_COMMIT_SHA\"\>$CI_COMMIT_SHORT_SHA\<\/a\>/g"
    {} \;
  after_script:
  - *post-process-log-files
  artifacts:
    name: $CI_JOB_NAME-$CI_JOB_ID
    paths:
    - '*.log'
    - coverage_report/
    when: always
    expire_in: 30 days
  rules:
  - if: $GITLAB_SCHEDULER_TYPE == "3"

# This kind of job is started by a daily scheduler, with the variable
# $GITLAB_SCHEDULER_TYPE = "1"
# Full tests are performed.
.buildtest_daily:
  extends: .buildtest_base
  rules:
  - if: $GITLAB_SCHEDULER_TYPE == "1"


# This kind of job is started by a daily scheduler, with the variable
# $GITLAB_SCHEDULER_TYPE = "1"
# Debug tests are performed.
.buildtest_daily_debug:
  extends: .buildtest_base
  variables:
    CTEST_BUILD_TYPE_GITLAB: debug
  rules:
  - if: $GITLAB_SCHEDULER_TYPE == "1"

# codeclimate job
.codeclimate:
  stage: checkcode
  image: $CI_REGISTRY_IMAGE/$BACI_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  script:
  - *clean-build-folder
  - mkdir ../baci-build/ && cd ../baci-build/
    # configure to get a compilation database
  - ${CMAKE_COMMAND} ${CI_PROJECT_DIR} -DBACI_BUILD_READTHEDOCS=OFF --preset=${CTEST_BUILD_PRESETS_RELEASE_GITLAB}
    # create  and activate virtual environment
  - python3 -m venv venv
  - . venv/bin/activate
  - pip install wheel
  - pip install -r ${CI_PROJECT_DIR}/utilities/code_climate/requirements.txt
    # create temporary directory for the yaml files from clang-tidy
  - mkdir clang-tidy-issues
    # get extra arguments for mpi
  - get_mpi_extra_args() { OUT="`OMPI_CXX=clang++ mpic++ --showme:compile`"; for i
    in $OUT; do echo -n "-extra-arg=$i "; done; echo;}
  - ESCAPED_PROJECT_DIR=$(echo "${CI_PROJECT_DIR}" | sed 's/\//\\\//g')
    # run clang tidy and export report
  - python ${CI_PROJECT_DIR}/utilities/code_climate/run-clang-tidy.py -j `nproc` -p
    . `get_mpi_extra_args` -export-fixes ./clang-tidy-issues/ -header-filter "${ESCAPED_PROJECT_DIR}\/.*"
    "${ESCAPED_PROJECT_DIR}\/.*" | python ${CI_PROJECT_DIR}/utilities/code_climate/filter_clang_tidy_output.py
    # export clang tidy issues
  - python ${CI_PROJECT_DIR}/utilities/code_climate/export_clang_tidy_issues.py -j
    `nproc` --code-climate-file ${CI_PROJECT_DIR}/codeclimate.json --source-folder
    ${CI_PROJECT_DIR} ./clang-tidy-issues/*.yaml
  - cd ${CI_PROJECT_DIR}
  variables:
    CTEST_BUILD_PRESETS_RELEASE_GITLAB: docker
    CMAKE_COMMAND: cmake
  artifacts:
    paths: [codeclimate.json]
    reports:
      codequality: codeclimate.json
  tags:
  - codeclimate
  needs:
  - job: build-base-dependencies
    optional: true

# Doxygen job
.doxygen:
  stage: documentation
  script:
  - echo Doxygen
    # Delete old build files.
  - rm -rf ../baci-build/
  - mkdir -p ${CI_PROJECT_DIR}/../baci-build && cd ${CI_PROJECT_DIR}/../baci-build

    # Configure and build (setting BACI_BUILD_READTHEDOCS=OFF, so that we don't need the python virtual environment
  - ${CMAKE_COMMAND} ${CI_PROJECT_DIR} --preset=${CTEST_BUILD_PRESETS_RELEASE_GITLAB}
    -DBACI_BUILD_READTHEDOCS=OFF
  - ${CMAKE_COMMAND} --build . --target doxygen > ${CI_PROJECT_DIR}/doxygen.log

    # Throw error if there are Latex errors in doxygen comments. Latex errors can be uniquely identified by a line starting with "! ".
  - if grep -qE '^[eE]rror:' ${CI_PROJECT_DIR}/doxygen.log; then echo 'Found at least
    one fatal error during doxygen generation.'; exit 1; else echo 'Doxygen builds
    without fatal errors.'; fi
  - if grep -qE '^! ' ${CI_PROJECT_DIR}/doxygen.log; then echo "Found at least one
    LaTeX error during doxygen build."; exit 1; else echo "Doxygen builds without
    LaTeX errors."; fi
    # Move final doxygen into the base folder for the next stage
  - mv $CI_PROJECT_DIR/../baci-build/doc/doxygen/html $CI_PROJECT_DIR/doxygen
  after_script:
    # Write Selection of the output into the terminal and therefore to GITLAB
  - sed -n '/* Extra verbosity turned on/,/Test project /p' ${CI_PROJECT_DIR}/doxygen.log
    # Write information about possible Latex errors to terminal
  - if grep -qE '^! ' ${CI_PROJECT_DIR}/doxygen.log; then echo "Found at least one
    LaTeX error during doxygen build."; else echo "Doxygen builds without LaTeX errors.";
    fi
    # Move the log file to the source folder, so it can be found by artifacts.
  variables:
    CTEST_BUILD_PRESETS_RELEASE_GITLAB: docker
    CMAKE_COMMAND: cmake

# ReadTheDocs job
.readthedocs:
  stage: documentation
  script:
  - echo Create ReadTheDocs documentation
    # loading python virtual environment
  - cd ${CI_PROJECT_DIR}
  - ./create-baci-python-venv
    # Delete old build files.
  - rm -rf ../baci-build/
  - mkdir -p ${CI_PROJECT_DIR}/../baci-build && cd ${CI_PROJECT_DIR}/../baci-build

    # Configure and build
  - ${CMAKE_COMMAND} ${CI_PROJECT_DIR} --preset=${CTEST_BUILD_PRESETS_RELEASE_GITLAB}
  - ${CMAKE_COMMAND} --build . --target readthedocs | tee ${CI_PROJECT_DIR}/readthedocs.log

    # Throw error if there are errors (or Warnings treated as errors) in readthedocs comments.
  - if grep -qE 'ERROR|treated as error:' ${CI_PROJECT_DIR}/readthedocs.log; then
    echo 'Found at least one fatal error during readthedocs generation.'; exit 1;
    else echo 'ReadTheDocs documentation builds without fatal errors.'; fi
    # Move final readthedocs into the base folder for the next stage
  - mv $CI_PROJECT_DIR/../baci-build/doc/readthedocs/html $CI_PROJECT_DIR/readthedocs
  after_script:
    # Write Selection of the output into the terminal and therefore to GITLAB
  - sed -n '/* Extra verbosity turned on/,/Test project /p' ${CI_PROJECT_DIR}/readthedocs.log
    # Move the log file to the source folder, so it can be found by artifacts.
  variables:
    CTEST_BUILD_PRESETS_RELEASE_GITLAB: docker
    CMAKE_COMMAND: cmake

#-------------------------------------------------------------------------------
# Stages during testing.
#-------------------------------------------------------------------------------

# We use stages just for grouping jobs into different categories. Dependencies are defined using the
# `needs` keyword to reduce the time of a pipeline run, see the Gitlab documentation about Directed
# Acyclic Graph Pipelines (https://docs.gitlab.com/ee/ci/pipelines/pipeline_architectures.html#directed-acyclic-graph-pipelines).
stages:
- build-docker-images
- checkcode
- buildtest
- documentation
- pages

#-------------------------------------------------------------------------------
# Actual jobs for testing.
#-------------------------------------------------------------------------------

# ALL---------------------------------------------------------------------------

checkcode:
  stage: checkcode
  image: $CI_REGISTRY_IMAGE/$BACI_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  script:
  - echo code check
  - ./create-baci-python-venv
  - bash utilities/code_checks/check_format_and_header
  artifacts:
    name: $CI_JOB_NAME-$CI_JOB_ID
    paths:
    - wrong_*.txt
    when: on_failure
    expire_in: 1 day
  rules:
  - if: $GITLAB_SCHEDULER_TYPE == "3" || $GITLAB_SCHEDULER_TYPE == "4"
    when: never
  - if: $CI_PIPELINE_SOURCE == "web"
  - if: $CI_MERGE_REQUEST_IID
  - if: $CI_PIPELINE_SOURCE == "schedule"
  tags:
  - checkcode
  interruptible: true
  needs:
  - job: build-base-dependencies
    optional: true

# Include a pre-configured danger bot job at a fixed version. Verbatim copy of:
# https://gitlab.com/gitlab-org/quality/pipeline-common/-/raw/7.5.1/ci/danger-review.yml
#
# This job supports the following variables:
# - DANGER_GITLAB_API_TOKEN: (Optional) A project access token with `api` scope.
# - GITLAB_DANGERFILES_VERSION: (Optional) Version requirement for `gitlab-dangerfiles`. Latest version if empty.
danger-review:
  rules:
  - if: $CI_PIPELINE_SOURCE == "merge_request_event"
  image: ruby:3.0
  stage: checkcode
  tags:
  - danger
  interruptible: true
  needs: []
  retry:
    max: 2
    when:
    - unknown_failure
    - api_failure
    - runner_system_failure
    - stuck_or_timeout_failure
  before_script:
  - bundle install --gemfile="./utilities/danger/Gemfile"
  - apt-get update && apt-get install -y python3-venv
    # create  and activate virtual environment
  - python3 -m venv venv
  - . venv/bin/activate
  - pip install wheel
  - pip install -r ${CI_PROJECT_DIR}/utilities/danger/requirements.txt
  script:
  - |
    danger_id=$(echo -n ${DANGER_GITLAB_API_TOKEN} | md5sum | awk '{print $1}' | cut -c5-10);
    BUNDLE_GEMFILE=./utilities/danger/Gemfile bundle exec danger --fail-on-errors=true --verbose --danger_id="${danger_id}" --dangerfile="./utilities/danger/Dangerfile";


# IMCS--------------------------------------------------------------------------

imcs-buildtest_daily_ubuntu20:
  extends: .buildtest_daily
  variables:
    CTEST_BUILD_PRESETS_RELEASE_GITLAB: imcs_workstation
    CMAKE_COMMAND: /imcs/public/compsim/opt/cmake-3.25.2/bin/cmake
    CTEST_COMMAND: /imcs/public/compsim/opt/cmake-3.25.2/bin/ctest
  tags:
  - imcs-nightly-full-ubuntu20
  needs: []

imcs-buildtest_daily_debug_ubuntu20:
  extends: .buildtest_daily_debug
  variables:
    CTEST_BUILD_PRESETS_DEBUG_GITLAB: imcs_workstation_optimized_debug
    CMAKE_COMMAND: /imcs/public/compsim/opt/cmake-3.25.2/bin/cmake
    CTEST_COMMAND: /imcs/public/compsim/opt/cmake-3.25.2/bin/ctest
  tags:
  - imcs-nightly-debug-ubuntu20
  needs: []

# Docker---------------------------------------------------------------------------

codeclimate:
  extends: .codeclimate
  rules:
  - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
  - if: $CI_PIPELINE_SOURCE == "schedule"

codeclimate-mr:
  extends: .codeclimate
  rules:
  - if: $CI_PIPELINE_SOURCE == "web"
  - if: $CI_MERGE_REQUEST_IID
  interruptible: true

buildtest_coverage:
  extends: .buildtest_coverage
  image: $CI_REGISTRY_IMAGE/$BACI_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  variables:
    # increase the global test timeout
    GLOBAL_TEST_TIMEOUT_SCALE: '50'
    # increase the unit test timeout
    UNITTEST_TIMEOUT: '50'
    # enable coverage option of ctest
    CTEST_BUILD_PRESETS_RELEASE_GITLAB: docker_coverage
    CMAKE_COMMAND: cmake
    CTEST_COMMAND: ctest
  tags:
  - coverage
  needs: []

pages: # job name needs to be pages
  stage: pages
  image: alpine:3.18
  # Download Doxygen and ReadTheDocs from previous documentation stage
  needs:
  - job: build-base-dependencies
    optional: true
  - job: doxygen
    artifacts: true
  - job: readthedocs
  before_script: []
  script:
    # Create python venv for gitlab api and anybadges
  - apk add python3 curl unzip git
  - python3 -m venv venv
  - . venv/bin/activate
  - pip install -r utilities/coverage/requirements.txt
    # Download latest coverage report
  - LATEST_ARTIFACT_URL="`python ./utilities/coverage/get_latest_artifacts_url_by_jobname.py
    $CI_SERVER_URL $ACCESS_TOKEN $CI_PROJECT_ID $CI_DEFAULT_BRANCH buildtest_coverage`"
  - 'curl --location --output coverage_artifacts.zip --header "PRIVATE-TOKEN: $ACCESS_TOKEN"
    "$LATEST_ARTIFACT_URL"'
  - unzip coverage_artifacts.zip -d coverage_artifacts
    # Print measured coverage rate
  - grep "Overall coverage rate:" -A 2 coverage_artifacts/genhtml_coverage.log
    # Create directory that will be published
  - mkdir -p public
    # move created coverage report to public folder (which is the path for GitLab Pages content)
  - mv coverage_artifacts/coverage_report public/coverage_report
    # Move most recent doxygen to public folder
  - mv doxygen public/doxygen
    # Move most recent readthedocs to public folder
  - mv readthedocs public/readthedocs
  - pip install anybadge
    # Create doxygen badge
  - anybadge -l doxygen -v ok --color=green -f public/doxygen.svg
    # Create readthedocs badge
  - anybadge -l readthedocs -v ok --color=green -f public/readthedocs.svg
    # Create website badge
  - anybadge -l website -v ok --color=green -f public/website.svg
  coverage: /lines\.*:\s+\d+\.\d+/
  artifacts:
    # store the public path in artifact
    # this is needed since in a subsequent deploy stage (automatically generated by GitLab)
    # the content of the below artifact is published on GitLab Pages
    paths:
    - public
    expire_in: 1 day
  rules:
  - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
  tags:
  - pages

doxygen:
  extends: .doxygen
  image: $CI_REGISTRY_IMAGE/$BACI_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  variables:
    CTEST_BUILD_PRESETS_RELEASE_GITLAB: docker
    CMAKE_COMMAND: cmake
  tags:
  - doxygen
  artifacts:
    name: $CI_JOB_NAME-$CI_JOB_ID
    paths:
    - doxygen/
    - doxygen.log
    when: always
    expire_in: 1 day
  interruptible: true
  rules:
  - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
  - if: $CI_PIPELINE_SOURCE == "schedule"
  - if: $CI_PIPELINE_SOURCE == "web"
  - if: $CI_MERGE_REQUEST_IID
  needs:
  - job: build-base-dependencies
    optional: true

# Build the docker image with all dependencies for Baci
build-base-dependencies:
  stage: build-docker-images
  tags:
  - build-docker-image
  image: docker:20.10.16
  services:
  - docker:20.10.16-dind
  before_script:
  - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
  - *compute-dependencies-hash
  - echo $CI_REGISTRY_IMAGE
  - echo $CI_REGISTRY
  - echo "Generating BACI dependencies docker image with version-hash $COMPUTED_DOCKER_DEPENDENCIES_HASH"
  - FULL_IMAGE_PATH="$CI_REGISTRY_IMAGE/$BACI_DOCKER_DEPENDENCIES_IMAGE:$COMPUTED_DOCKER_DEPENDENCIES_HASH"
  - docker build --no-cache --tag $FULL_IMAGE_PATH --file docker/Dockerfile .
  - docker push $FULL_IMAGE_PATH
  rules:
  - if: $BACI_DOCKER_BUILD_IMAGES == "True"
    when: manual

buildtest_full_release:
  extends: .buildtest_full
  image: $CI_REGISTRY_IMAGE/$BACI_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  variables:
    CTEST_BUILD_PRESETS_RELEASE_GITLAB: docker
    CTEST_BUILD_PRESETS_DEBUG_GITLAB: docker_debug
    CMAKE_COMMAND: cmake
    CTEST_COMMAND: ctest
  tags:
  - buildtest
  needs:
  - job: build-base-dependencies
    optional: true
  # Make use of evaluation order to run test in nightly pipeline as well
  rules:
  - if: $GITLAB_SCHEDULER_TYPE == "1"
  - !reference [.buildtest_full, rules]
  interruptible: true

buildtest_full_release_asan:
  extends: .buildtest_full
  image: $CI_REGISTRY_IMAGE/$BACI_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  variables:
    GLOBAL_TEST_TIMEOUT_SCALE: '10'
    CTEST_BUILD_PRESETS_RELEASE_GITLAB: docker_asan
    CMAKE_COMMAND: cmake
    CTEST_COMMAND: ctest
  after_script:
  - *post-process-log-files
  - ${CI_PROJECT_DIR}/utilities/grep_asan_failures.sh ${CI_PROJECT_DIR}/test.log >
    ${CI_PROJECT_DIR}/asan_summary.log
  tags:
  - buildtest
  needs:
  - job: build-base-dependencies
    optional: true
  # This job only runs in nightly builds
  rules:
  - if: $GITLAB_SCHEDULER_TYPE == "1"
  interruptible: true


buildtest_full_debug:
  extends: .buildtest_daily_debug
  image: $CI_REGISTRY_IMAGE/$BACI_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  variables:
    CTEST_BUILD_PRESETS_DEBUG_GITLAB: docker_debug
    CMAKE_COMMAND: cmake
    CTEST_COMMAND: ctest
  tags:
  - buildtest-debug
  needs:
  - job: build-base-dependencies
    optional: true
  rules:
  - if: $GITLAB_SCHEDULER_TYPE == "1"
  - !reference [.buildtest_full, rules]
  interruptible: true

build-verify-headers:
  image: $CI_REGISTRY_IMAGE/$BACI_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  variables:
    NUMBER_OF_BUILD_THREADS: '10'
    CMAKE_COMMAND: cmake
  tags:
  - verify-headers
  needs:
  - job: build-base-dependencies
    optional: true
  stage: checkcode
  script:
  - mkdir -p ${CI_PROJECT_DIR}/../baci-build
    # configure
  - |
    cd ${CI_PROJECT_DIR}
    ./create-baci-python-venv
    cd ${CI_PROJECT_DIR}/../baci-build
    # Configure verification of header sets.
    ${CMAKE_COMMAND} ${CI_PROJECT_DIR} --preset=docker -DCMAKE_VERIFY_INTERFACE_HEADER_SETS="ON"
    # verify headers
  - time ${CMAKE_COMMAND} --build . --target all_verify_interface_header_sets -- -j
    `nproc` 2>&1 | tee ${CI_PROJECT_DIR}/verify_headers.log
  artifacts:
    name: $CI_JOB_NAME-$CI_JOB_ID
    paths:
    - '*.log'
    when: on_failure
    expire_in: 1 day
  rules:
  - !reference [checkcode, rules]
  interruptible: true

readthedocs:
  extends: .readthedocs
  image: $CI_REGISTRY_IMAGE/$BACI_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  variables:
    CTEST_BUILD_PRESETS_RELEASE_GITLAB: docker
    CMAKE_COMMAND: cmake
  tags:
  - readthedocs
  artifacts:
    name: $CI_JOB_NAME-$CI_JOB_ID
    paths:
    - readthedocs/
    - readthedocs.log
    when: always
    expire_in: 1 day
  interruptible: true
  rules:
  - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
  - if: $CI_PIPELINE_SOURCE == "schedule"
  - if: $CI_PIPELINE_SOURCE == "web"
  - if: $CI_MERGE_REQUEST_IID
  needs:
  - job: build-base-dependencies
    optional: true

# The Trilinos pipeline with a specific commit ref runs via a schedule or when manually triggered
build-base-dependencies-trilinos-develop:
  stage: build-docker-images
  tags:
  - build-docker-image
  image: docker:20.10.16
  services:
  - docker:20.10.16-dind
  before_script:
  - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
  - echo "Generating BACI dependencies docker image with Trilinos version $TRILINOS_PIPELINE_COMMIT_REF"
  - FULL_IMAGE_PATH="$CI_REGISTRY_IMAGE/$BACI_DOCKER_DEPENDENCIES_IMAGE_TRILINOS"
  - docker build --no-cache --build-arg NPROCS=`nproc` --build-arg TRILINOS_VERSION="$TRILINOS_PIPELINE_COMMIT_REF"
    --tag $FULL_IMAGE_PATH --file docker/trilinos_develop/Dockerfile .
  - docker push $FULL_IMAGE_PATH
  rules:
  - if: $GITLAB_SCHEDULER_TYPE == "4"
  interruptible: true

buildtest_full_release_trilinos_develop:
  extends: .buildtest_full
  image: $CI_REGISTRY_IMAGE/$BACI_DOCKER_DEPENDENCIES_IMAGE_TRILINOS
  variables:
    CTEST_BUILD_PRESETS_RELEASE_GITLAB: docker
    CTEST_BUILD_PRESETS_DEBUG_GITLAB: docker_debug
    CMAKE_COMMAND: cmake
    CTEST_COMMAND: ctest
  tags:
  - buildtest
  needs:
  - job: build-base-dependencies-trilinos-develop
    optional: true
  rules:
  - if: $GITLAB_SCHEDULER_TYPE == "4"
  interruptible: true

buildtest_full_debug_trilinos_develop:
  extends: .buildtest_daily_debug
  image: $CI_REGISTRY_IMAGE/$BACI_DOCKER_DEPENDENCIES_IMAGE_TRILINOS
  variables:
    CTEST_BUILD_PRESETS_DEBUG_GITLAB: docker_debug
    CMAKE_COMMAND: cmake
    CTEST_COMMAND: ctest
  tags:
  - buildtest-debug
  needs:
  - job: build-base-dependencies-trilinos-develop
    optional: true
  rules:
  - if: $GITLAB_SCHEDULER_TYPE == "4"
  interruptible: true
