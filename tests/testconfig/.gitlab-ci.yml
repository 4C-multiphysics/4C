#-------------------------------------------------------------------------------
# General rules when to create a pipeline
# N.B. This doesn't say anything about which jobs are run but only determines
# if a pipeline is created.
workflow:
  name: $FOUR_C_PIPELINE_NAME
  rules:
    - if: $CI_COMMIT_TAG
      variables:
        FOUR_C_PIPELINE_NAME: Tag pipeline for '$CI_COMMIT_TAG'

#-------------------------------------------------------------------------------
# Define global variables for all jobs
variables:
  # Clone repository by default, file have changed attribute.
  GIT_STRATEGY: clone

  GITLAB_PIPELINE_TYPE:
    value: trilinos develop
    description: Type of pipeline
    options: [coverage, trilinos develop]

  # Hash of all relevant dependencies for the docker image
  FOUR_C_DOCKER_DEPENDENCIES_HASH: bbac1cd9

  # Variables for Trilinos pipeline
  # The default Trilinos commit ref the Trilinos pipeline is running on
  TRILINOS_PIPELINE_COMMIT_REF: develop
  FOUR_C_DOCKER_DEPENDENCIES_IMAGE_TRILINOS: 4c-dependencies-trilinos:$TRILINOS_PIPELINE_COMMIT_REF

.compute_dependencies_hash: &compute_dependencies_hash
  # compute short hash from contents of folder dependencies and docker (exclude trilinos_config and README.md files)
  - COMPUTED_DOCKER_DEPENDENCIES_HASH=`./docker/compute_dependencies_hash.sh`

before_script:
  - git config --global --add safe.directory ${CI_PROJECT_DIR}
  - *compute_dependencies_hash
  - if [ "${COMPUTED_DOCKER_DEPENDENCIES_HASH}" != "$FOUR_C_DOCKER_DEPENDENCIES_HASH" ]; then echo "Docker
    image version hash does not match the hash of the dependencies. You likely need to change the hash
    to ${COMPUTED_DOCKER_DEPENDENCIES_HASH} and rebuild the dependencies." && exit 1; else echo "Running
    on the correct docker image version with hash $FOUR_C_DOCKER_DEPENDENCIES_HASH."; fi

.build-only: &build-only
  - mkdir -p ${CI_PROJECT_DIR}/build
  # configure
  - |
    cd ${CI_PROJECT_DIR}/build
    cmake ${CI_PROJECT_DIR} --fresh --preset=${CMAKE_PRESET}
  - echo Building the following targets ${BUILD_TARGETS}
  # build
  - time cmake --build . --target ${BUILD_TARGETS} -- -j `nproc` 2>&1 | tee ${CI_PROJECT_DIR}/build.log

.build-and-test: &build-and-test
  - *build-only
  # test
  - time ctest -VV -j `nproc` --output-on-failure --output-junit ${CI_PROJECT_DIR}/junit_test_summary.xml
  - cd ${CI_PROJECT_DIR}

# Generic job that builds and tests the project. Derived jobs may configure the details via variables.
.buildtest_base:
  stage: buildtest
  variables:
    # So the old build can be used again.
    GIT_STRATEGY: fetch
    BUILD_TARGETS: full
  script:
    - rm -rf ${CI_PROJECT_DIR}/build/
    - *build-and-test
  artifacts:
    name: $CI_JOB_NAME-$CI_JOB_ID
    paths:
      - '*.log'
      - junit_test_summary.xml
    reports:
      junit: junit_test_summary.xml
    when: always
    expire_in: 1 day

#-------------------------------------------------------------------------------
# Stages during testing.
#-------------------------------------------------------------------------------

# We use stages just for grouping jobs into different categories. Dependencies are defined using the
# `needs` keyword to reduce the time of a pipeline run, see the Gitlab documentation about Directed
# Acyclic Graph Pipelines (https://docs.gitlab.com/ee/ci/pipelines/pipeline_architectures.html#directed-acyclic-graph-pipelines).
stages:
  - build-docker-images
  - buildtest
  - pages

# Full tests with coverage are performed and a coverage report is created
buildtest_coverage:
  stage: buildtest
  image: ghcr.io/4c-multiphysics/4c-dependencies-ubuntu24.04:$FOUR_C_DOCKER_DEPENDENCIES_HASH
  variables:
    BUILD_TARGETS: full
    # enable coverage option of ctest
    CMAKE_PRESET: docker_coverage
  script:
    - rm -rf ${CI_PROJECT_DIR}/build/
    - *build-and-test
    # generate the coverage_base.info: the "baseline" coverage data file that contains zero coverage for every instrumented line.
    - lcov --capture --initial --no-external --directory build/ --base-directory . --output-file coverage_base.info
      > ${CI_PROJECT_DIR}/coverage_base.log
    # generate the coverage_tests.info based on tests run above
    - lcov --capture --no-external --directory build/ --base-directory . --output-file coverage_tests.info
      > ${CI_PROJECT_DIR}/coverage_tests.log
    # combine the baseline coverage with the coverage from the tests
    - lcov --add-tracefile coverage_base.info --add-tracefile coverage_tests.info --output-file coverage.info  >
      ${CI_PROJECT_DIR}/coverage.log
    # remove unwanted files from the coveragre report
    - lcov --remove coverage.info "*/unittests*/*" "*/tests/*" "*/build/*" -o coverage_filtered.info >
      ${CI_PROJECT_DIR}/coverage_filtered.log
    # generate the html version of the coverage report
    - genhtml coverage_filtered.info --legend --demangle-cpp --output-directory coverage_report/ --title
      "4C commit $CI_COMMIT_SHORT_SHA" | tee ${CI_PROJECT_DIR}/genhtml_coverage.log
    # add repo link to the commit that the report is based on
    - find coverage_report/ -type f -exec sed -i "s/4C commit $CI_COMMIT_SHORT_SHA/4C commit  \<a href=\"https:\/\/gitlab.lrz.de\/baci\/baci\/commit\/$CI_COMMIT_SHA\"\>$CI_COMMIT_SHORT_SHA\<\/a\>/g"
      {} \;
  artifacts:
    name: $CI_JOB_NAME-$CI_JOB_ID
    paths:
      - '*.log'
      - coverage_report/
    when: always
    expire_in: 30 days
  rules:
    - if: $GITLAB_PIPELINE_TYPE == "coverage"
  tags:
    - coverage
  needs: []

pages: # job name needs to be pages
  stage: pages
  image: alpine:3.18
  # Download Doxygen and ReadTheDocs from previous documentation stage
  needs:
    - job: buildtest_coverage
  before_script: []
  script:
    # Print measured coverage rate
    - grep "Overall coverage rate:" -A 2 coverage_report/genhtml_coverage.log
    # Create directory that will be published
    - mkdir -p public
    # Move most recent doxygen to public folder
    - mv coverage_report public/coverage_report
  coverage: /lines\.*:\s+\d+\.\d+/
  artifacts:
    # store the public path in artifact
    # this is needed since in a subsequent deploy stage (automatically generated by GitLab)
    # the content of the below artifact is published on GitLab Pages
    paths:
      - public
    expire_in: 1 day
  rules:
    - if: $GITLAB_PIPELINE_TYPE == "coverage"
  tags:
    - pages

# The Trilinos pipeline with a specific commit ref runs via a schedule or when manually triggered
build_base_dependencies_trilinos_develop:
  stage: build-docker-images
  tags:
    - build-docker-image
  image: docker:20.10.16
  services:
    - docker:20.10.16-dind
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - echo "Generating 4C dependencies docker image with Trilinos version $TRILINOS_PIPELINE_COMMIT_REF"
    - FULL_IMAGE_PATH="$CI_REGISTRY_IMAGE/$FOUR_C_DOCKER_DEPENDENCIES_IMAGE_TRILINOS"
    - docker build --no-cache --build-arg NPROCS=`nproc` --build-arg TRILINOS_VERSION="$TRILINOS_PIPELINE_COMMIT_REF"
      --tag $FULL_IMAGE_PATH --file docker/trilinos_develop/Dockerfile .
    - docker push $FULL_IMAGE_PATH
  rules:
    - if: $GITLAB_PIPELINE_TYPE == "trilinos develop"
  interruptible: true

gcc9_trilinos_develop:
  extends: .buildtest_base
  image: $CI_REGISTRY_IMAGE/$FOUR_C_DOCKER_DEPENDENCIES_IMAGE_TRILINOS
  variables:
    CMAKE_PRESET: docker
  tags:
    - buildtest
  needs:
    - job: build_base_dependencies_trilinos_develop
      optional: true
  rules:
    - if: $GITLAB_PIPELINE_TYPE == "trilinos develop"
  interruptible: true

gcc9_assertions_trilinos_develop:
  extends: .buildtest_base
  image: $CI_REGISTRY_IMAGE/$FOUR_C_DOCKER_DEPENDENCIES_IMAGE_TRILINOS
  variables:
    CMAKE_PRESET: docker_assertions
  tags:
    - buildtest
  needs:
    - job: build_base_dependencies_trilinos_develop
      optional: true
  rules:
    - if: $GITLAB_PIPELINE_TYPE == "trilinos develop"
  interruptible: true
